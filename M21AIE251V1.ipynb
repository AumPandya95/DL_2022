{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 366)\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_path = Path().resolve()\n",
    "img = Image.open(f'{root_path}/data/training/aeroplane/2007_000033.jpg')\n",
    "print(img.size)\n",
    "# img\n",
    "maxPixel = 128\n",
    "imScalled = img.resize((maxPixel,maxPixel))\n",
    "img_pixel = np.reshape(list(imScalled.getdata()),(maxPixel,maxPixel,3))\n",
    "img_pixel\n",
    "print(img_pixel.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 images belonging to 2 classes.\n",
      "Found 723 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 08:43:16.518326: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-04 08:43:16.551510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-04 08:43:16.552505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 980M computeCapability: 5.2\n",
      "coreClock: 1.1265GHz coreCount: 12 deviceMemorySize: 7.94GiB deviceMemoryBandwidth: 149.31GiB/s\n",
      "2022-09-04 08:43:16.552606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.552700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.552782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.552866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.552980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.553094: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.553175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.553254: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-04 08:43:16.553267: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-04 08:43:16.553560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-04 08:43:16.553861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-04 08:43:16.553875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "maxPixel=128\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "valid_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(os.path.join(root_path, 'data/training'),  batch_size=200, class_mode = 'binary', target_size = (img.size[0], img.size[1]),classes=['aeroplane','others'])\n",
    "valid_generator = valid_datagen.flow_from_directory(os.path.join(root_path, 'data/validation'),  batch_size=200, class_mode = 'binary', target_size = (img.size[0], img.size[1]),classes=['aeroplane','others'])\n",
    "\n",
    "#train_generator = train_datagen.flow_from_directory(os.path.join(root_path, 'data/training'),  batch_size=20, class_mode = 'binary', target_size = (maxPixel, maxPixel),classes=['aeroplane','others'])\n",
    "#valid_generator = valid_datagen.flow_from_directory(os.path.join(root_path, 'data/validation'),  batch_size=20, class_mode = 'binary', target_size = (maxPixel, maxPixel),classes=['aeroplane','others'])\n",
    "\n",
    "base_model = InceptionV3(input_shape = (img.size[0], img.size[1], 3), include_top = False, weights = 'imagenet', classes=20)\n",
    "#base_model = InceptionV3(input_shape = (maxPixel, maxPixel, 3), include_top = False, weights = 'imagenet', classes=20)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 14, 10, 2048) dtype=float32 (created by layer 'mixed10')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 08:43:18.685117: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1146880000 exceeds 10% of free system memory.\n",
      "2022-09-04 08:43:19.181434: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1146880000 exceeds 10% of free system memory.\n",
      "2022-09-04 08:43:19.340334: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1146880000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "#x = Dense(1000, activation='relu')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "549000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Flatten()(model.output))\n",
    "500*366*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 87s 87s/step - loss: 4.5430 - acc: 0.0000e+00 - val_loss: 0.7202 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 4.4537 - acc: 0.0000e+00 - val_loss: 0.6088 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 4.3698 - acc: 0.0000e+00 - val_loss: 0.5791 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 87s 87s/step - loss: 4.3366 - acc: 0.0000e+00 - val_loss: 0.6124 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 4.3221 - acc: 0.0000e+00 - val_loss: 0.6723 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 87s 87s/step - loss: 4.3057 - acc: 0.0000e+00 - val_loss: 0.5145 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 4.2504 - acc: 0.0000e+00 - val_loss: 0.5734 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 88s 88s/step - loss: 4.1971 - acc: 0.0000e+00 - val_loss: 0.5648 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 4.1432 - acc: 0.0000e+00 - val_loss: 0.5496 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 87s 87s/step - loss: 4.0791 - acc: 0.0000e+00 - val_loss: 0.4960 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "plane_detector = model.fit(\n",
    "    train_generator, \n",
    "    validation_data=valid_generator, \n",
    "    steps_per_epoch=1,\n",
    "#     validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(\n",
    "    data_generator: str,\n",
    "    feature_dimension: float = 1000.,\n",
    "    sample_size: int = 83,\n",
    "    batch_size: int = 200\n",
    "):\n",
    "    features = np.zeros(shape=(sample_size, feature_dimension))  # Must be equal to the output of the model\n",
    "    labels = np.zeros(shape=(sample_size))\n",
    "    \n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in data_generator:\n",
    "        features_batch = model.predict(inputs_batch)\n",
    "        if features_batch.shape[0] != batch_size:\n",
    "            features[i * batch_size:] = features_batch\n",
    "            labels[i * batch_size:] = labels_batch\n",
    "        else:\n",
    "            features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "            labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_size:\n",
    "            break\n",
    "    \n",
    "    return features, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train features\n",
    "train_features, train_labels = get_features(\n",
    "    data_generator=train_generator,\n",
    "    feature_dimension=1000,\n",
    "    sample_size=83,\n",
    "    batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation features\n",
    "validation_features, validation_labels = get_features(\n",
    "    data_generator=valid_generator,\n",
    "    feature_dimension=1000,\n",
    "    sample_size=723,\n",
    "    batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1000)\n",
      "(200, 1000)\n",
      "(200, 1000)\n",
      "(123, 1000)\n"
     ]
    }
   ],
   "source": [
    "features_validation = np.zeros(shape=(723, 1000))  # Must be equal to the output of the model\n",
    "labels_validation = np.zeros(shape=(723))\n",
    "\n",
    "# Pass data through convolutional base\n",
    "i = 0\n",
    "for inputs_batch_valid, labels_batch_valid in valid_generator:\n",
    "    features_batch_validation = model.predict(inputs_batch_valid)\n",
    "    print(features_batch_validation.shape)\n",
    "    if features_batch_validation.shape[0] != 200:\n",
    "        b_size = features_batch_validation.shape[0]\n",
    "        features_validation[i * 200:] = features_batch_validation\n",
    "        labels_validation[i * 200:] = labels_batch_valid\n",
    "    else:\n",
    "        features_validation[i * 200: (i + 1) * 200] = features_batch_validation\n",
    "        labels_validation[i * 200: (i + 1) * 200] = labels_batch_valid\n",
    "    i += 1\n",
    "    if i * 200 >= 723:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(features)\n",
    "X_test = sc.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network_env",
   "language": "python",
   "name": "neural_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a28f0cbfefa6cb02fbe4751e3ca4924b08333f24d18155855e9c7cbc1bce905"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
